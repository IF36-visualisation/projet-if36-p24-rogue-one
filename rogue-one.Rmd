---
title: "Rogue One project"
author: "JAULIN Maxence, PRODHON Louis, GIROD Mathis, WANG Zezhong"
output:
  html_document: default
---

```{r setup}
library(ggplot2)
library(dplyr)
library(tidyr)
library(tibble)
library(readr)
library(lubridate)
library(forcats)
library(stringr)
```

# Projet Rogue One

Ce projet a pour but de découvrir, traiter et analyser les données provenant de différents jeux de données provenants de la SNCF.

# Introduction

Nous avons décidés de nous concentrer sur les données récoltées par l'entreprise **SNCF**, entreprise ferroviaire française. Les données récoltées sur le transport sont assez importantes c'est pourquoi nous avons choisi de nous concentrer sur les gares et leurs données liées ainsi que les données de perte et vol et des voyageurs. Ces données sont toutes archivées sur le site web : [Data SNCF](https://data.sncf.com)

## Données

17 variables.

| --- | Nom de la variable      | Type     | Format              | Dataset (Origine) |
|---------------|---------------|---------------|---------------|---------------|
| 01  | gare                    | Nominale | String              | 1,2,3,4,5,6,7     |
| 02  | departement             | Ordinale | NN                  | 1                 |
| 03  | zone                    | Nominale | {A,B,C}             | 1                 |
| 04  | latitude                | Continue | M"S'NS              | 1                 |
| 05  | longitude               | Continue | M"S'NS              | 1                 |
| 06  | annee                   | Ordinale | YYYY                | 2,3,4             |
| 07  | timing_reception        | Discrète | YYYY-MM-DD-HH-MM-SS | 6,7               |
| 08  | nb_voyageurs            | Discrète | Integer             | 2                 |
| 09  | age                     | Ordinale | String              | 5                 |
| 10  | pourcentage_age         | Continue | \%                  | 5                 |
| 11  | csp                     | Nominale | String              | 4                 |
| 12  | pourcentage_csp         | Continue | \%                  | 4                 |
| 13  | motif_deplacement       | Nominale | String              | 3                 |
| 14  | pourcentage_deplacement | Continue | \%                  | 3                 |
| 15  | nature_objet            | Nominale | String              | 6,7               |
| 16  | categorie_objet         | Nominale | String              | 6,7               |
| 17  | code_uic                | Nominale | NNNNNNNNNN          | 6,7               |

**Nombre d'observations**

-   [dataset1-gares-de-voyageurs.csv](https://data.sncf.com/explore/dataset/gares-de-voyageurs/export/) (2.862)
-   [dataset2-frequentation-gares.csv](https://data.sncf.com/explore/dataset/frequentation-gares/export/) (21.147)
-   [dataset3-motif-deplacement.csv](https://data.sncf.com/explore/dataset/motif-deplacement/export/) (284)
-   [dataset4-enquetes-gares-connexions-repartition-par-repartition-par-categories-socio-profe.csv](https://data.sncf.com/explore/dataset/enquetes-gares-connexions-repartition-par-repartition-par-categories-socio-profe/export/) (697)
-   [dataset5-enquetes-gares-connexions-repartition-repartition-par-classe-dage.csv](https://data.sncf.com/explore/dataset/enquetes-gares-connexions-repartition-repartition-par-classe-dage/export/) (375)
-   [dataset6-objets-trouves-gares.csv](https://data.sncf.com/explore/dataset/objets-trouves-gares/export/)(1.844.912)
-   [dataset7-objets-trouves-restitution.csv](https://data.sncf.com/explore/dataset/objets-trouves-restitution/export/) (858.180)

Au sein de ces données nous constatons que toutes s'orchestrent autour d'une donnée principale (Gare, 01) qui est présent dans tous les datasets. Nous pouvons segmenter les données restantes par des critères géographiques (02,03,04,05), des critères temporels (06,07), des critères voyageurs (08,09,10,11,12,13,14) et des critères sur les objets perdus/trouvés (15,16,17).

## Plan d'analyse

Dans un premier temps, nous souhaitons concentrer notre effort sur la découverte du jeu de données et surtout sa compréhension. Nous entendons par cela de faire des visualisations sur le réseau ferroviaire actuel, son affluence, etc. Nous nous concentrerons ensuite sur une analyse des voyageurs puis celles des objets perdus

### Découverte

-   [ ] A quoi ressemble le réseau SNCF en France ?
-   [ ] Quels sont les départements les mieux équipés ?
-   [ ] A quel point Paris a une place importante dans le réseau des autres territoires ?

### Voyageurs

-   [ ] Le nombre de voyageurs est-il bien repartis entre les gares d'un même département ?
-   [ ] Quel est le voyageur moyen de la SNCF ?
-   [ ] Comment ce voyageur diffère en fonction des gares ?
-   [ ] Quel est la relation entre les motifs de voyage des passagers et leur répartition par âge et par profession ?

### Objets

-   [ ] Y-a-t-il plus de chances de perdre un objet selon la gare ?
-   [ ] Doit-on s'attendre à un afflux d'objets perdus plus important dans les mois de Juillet-Août 2024 plus important que les dernières années ?
-   [ ] Quelles sont les chances de retrouver un objet perdu ?
-   [ ] Quelles sont les chances de retrouver un objet en fonction de sa nature ?

## Ajouts possibles de l'équipe

Nous aimerions aussi ajouter des données créées personnellement pour visualiser le volume des objets que cela peut représenter comme par exemple un volume type par catégorie d'objet. De même, les données voyageurs sont assez faibles et l'équipe extrapolera sûrement certaines données afin de garder un sens à l'analyse de celles-ci.

# L'équipe du projet

[Maxence Jaulin](https://github.com/maxencejaulin) [Louis Prodhon](https://github.com/Grexiem) [Mathis Girod](https://github.com/girodmat) [Zezhong Wang](https://github.com/RubiesWzz)

### Première étape : du CSV aux datasets

Récupération des jeux de données SNCF :

-   Gares de voyageurs : gares

-   Fréquentation des gares : frequentation

-   Motif de déplacement des voyageurs : motif_depl

-   Catégorie socio-professionelle des voyageurs : CSP_voya

-   Classe d'âge des voyageurs : age_voya

-   Objets perdus : obj_perdus

-   Objets trouvés : obj_trouves

```{r}
gares <- read_delim(file = "data/dataset1-gares-de-voyageurs.csv", delim=";")
frequentation <- read_delim(file = "data/dataset2-frequentation-gares.csv", delim=";")
motif_depl <- read_delim(file = "data/dataset3-motif-deplacement.csv", delim=";")
CSP_voya <- read_delim(file = "data/dataset4-enquetes-gares-connexions-repartition-par-repartition-par-categories-socio-profe.csv", delim=";")
age_voya <- read_delim(file = "data/dataset5-enquetes-gares-connexions-repartition-repartition-par-classe-dage.csv", delim=";")
obj_perdus <- read_delim(file = "data/dataset6-objets-trouves-gares.csv", delim=";")
obj_trouves <- read_delim(file = "data/dataset7-objets-trouves-restitution.csv", delim=";")

```

**Fréquentation des gares**

Tout d'abord, voici un petit tour d'horizon du dataset frequentation.

```{r}
head(frequentation)
summary(frequentation)
```

Afin d'obtenir un classement des gares les plus fréquentés, nous avons choisi de filtrer le dataset afin de ne garder que les gares au dessus d'un seuil de 20.000.000 individus.

Ce filtre nous permet de faire ressortir les gares les plus fréquentées uniquement.

```{r}
freq <- frequentation %>%
  select(gare = "Nom de la gare", voyageurs = "Total Voyageurs + Non voyageurs 2022") %>%
  filter(voyageurs > 20000000)

ggplot(data = freq, mapping=aes(x=voyageurs,y=gare))+geom_col()
```

On remarque que les gares avec le plus d'affluence sont les gares parisiennes, ce qui n'est pas très étonnant étant donné que la grande majorité des trajets partent et viennent de Paris.

## Voyageurs

Afin de mieux comprendre les voyageurs, nous avons choisi de nous intéresser aux différents profils qui utilisent les trains des réseaux ferrés de France.

Dans un premier temps, nous analysons le nombre de voyageurs par département, pour nous intéresser ensuite à la proportion de voyageurs dans les gares au sein d'un même département.

*Le nombre de voyageurs est-il bien repartis entre les gares d'un même département ?*

**Nombre de voyageurs total par département (2022)**

```{r}
freq <- frequentation %>%
  rename(code_postal = 'Code postal')

freq <- freq %>%
  rename(passagers2022 = 'Total Voyageurs 2022')

freq <- freq %>%
  mutate(code_postal = as.character(code_postal))

frequentation <- freq %>%
  mutate(departement = substr(code_postal, 1, 2))

departement_passagers <- frequentation %>%
  group_by(departement) %>%
  summarize(total_passagers = sum(passagers2022))

ggplot(departement_passagers, aes(x = total_passagers, y = departement)) +
  geom_bar(stat = "identity") +
  labs(title = "Répartition des voyageurs entre les départements en 2022",
       x = "Nombre total de passagers",
       y = "Département") +
  theme(axis.text.y = element_text(size = 8))

```

Comme le constat fait un peu plus haut, on observe que la région Ile de France (composée des départements 75,77, 78, 91, 92, 93, 94) concentre la plupart de la fréquentation. Ce constat est tout à fait correct étant donné que la région concentre environ 12 millions de personnes.

On peut également créer une visualisation qui permettrait de connaitre la fréquentation de chacune des régions.

**Répartition du nombre de voyageurs dans les gares d'un même département.** Exemple département (77)

Grâce à cette visusalisation, on peut connaître les gares les plus importantes en termes de fréquentation dans chacun des départements.

Dans le cas du département 77 et du premier jet de visualisation, on observe que la gare de Melun est très fréquentée comparé aux autres gares.

```{r}
freq <- frequentation %>%
  rename(gare = 'Nom de la gare')

gares_77 <- freq %>%
  filter(departement == "77")

ggplot(gares_77, aes(x = gare, y = passagers2022)) +
  geom_bar(stat = "identity") +
  labs(title = "Repartition des voyageurs dans les gares du département 77 en 2022",
       x = "Gare",
       y = "Nombre de passagers") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))


```

Au sein du 77, on remarque des disparités entre les gares. Des gares comme celle de Melun ou Chartrette concentre toute la fréquentation au détriment de gares comme Bois-le-Roi.

On peut expliquer cela notamment après quelques recherches car en effet le RER D désert Melun à la différence de petites gares comme celle de Bois-le-Roi.

*Explorer la répartition par âge des passagers*

En raison de quelques problèmes dans l'ensemble de données, tels que des codes UIC incohérents et des variations dans les années de recensement et les données des stations, nous allons nous concentrer exclusivement sur la répartition par âge pour les années 2015, 2016 et 2017.

Conserver les colonnes spécifiées dans frequentation et renommer Code UIC en UIC et Filtrer le age_voya pour une année 2015,16,17.

```{r}
freq_selected <- frequentation %>%
  select(Nom = `Nom de la gare`, UIC = `Code UIC`, `Total Voyageurs 2015`, `Total Voyageurs 2016`, `Total Voyageurs 2017`)
age_filtered <- age_voya %>%
  filter(Année %in% c(2015, 2016, 2017)) %>%
  rename(Nom = `Gare enquêtée`)
```

Filtrer freq_selected par nom de station, en ne conservant que les lignes qui correspondent à Nom dans age_filtered, et vice versa.

```{r}
freq_matched <- semi_join(freq_selected, age_filtered, by = "Nom")
age_matched <- semi_join(age_filtered, freq_selected, by = "Nom")
```

Diviser les données dans freq_matched par année.

```{r}
freq_long <- freq_matched %>%
  pivot_longer(
    cols = c(`Total Voyageurs 2015`, `Total Voyageurs 2016`, `Total Voyageurs 2017`),
    names_to = "Année",
    values_to = "Total Voyageur",
    names_prefix = "Total Voyageurs "
  ) %>%
  mutate(Année = as.integer(Année))
```

Combinaison de données dans age_filtered par année.

```{r}
age_wide <- age_matched %>%
  pivot_wider(
    names_from = `Classe d'âge`, 
    values_from = Pourcentage, 
    values_fill = list(Pourcentage = 0)  
  )
```

Fusionner et supprimer les lignes contenant des données nulles.

```{r}
combined_dataset <- left_join(freq_long, age_wide, by = c("Nom", "Année"))
cleaned_dataset <- na.omit(combined_dataset)
```

Calculer le nombre de voyageurs dans chaque groupe d'âge et les nombre total pour chaque année

```{r}
age_columns <- c('19 ans et moins', '20 ans à 29 ans', '30 ans à 39 ans', '40 ans à 49 ans', '50 ans à 59 ans', '60 ans et plus')
cleaned_dataset <- cleaned_dataset %>%
  mutate(across(all_of(age_columns), ~ .x * `Total Voyageur` / 100, .names = "passengers_{.col}"))
age_passenger_totals <- cleaned_dataset %>%
  group_by(Année) %>%
  summarise(across(starts_with("passengers"), sum, .names = "total_{.col}"))
```

L'étape suivante consiste à calculer le pourcentage des groupes d'âge ainsi que la cartographie.

```{r}
age_passenger_totals_long <- age_passenger_totals %>%
  pivot_longer(
    cols = starts_with("total_passengers"),
    names_to = "Age_Group",
    values_to = "Total_Passengers",
    names_prefix = "total_passengers_"
  )
age_passenger_totals_long <- age_passenger_totals_long %>%
  group_by(Année) %>%
  mutate(Total_Passengers_Year = sum(Total_Passengers)) %>%
  ungroup() %>%
  mutate(Percentage = (Total_Passengers / Total_Passengers_Year) * 100)
ggplot(age_passenger_totals_long, aes(x = Année, y = Percentage, fill = Age_Group)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Percentage of Passengers by Age Group and Year",
       x = "Year",
       y = "Percentage (%)",
       fill = "Age Group") +
  theme_minimal()
```

**Qui est le voyageur moyen de la SNCF ?** ***Catégorie socio professionnelle*** Il est également intéressant de recueillir des informations sur le voyageur moyen de la SNCF, En premier lieu nous allons voir les différentes catégories socio professionnelles.

PS : Le Pourcentage correspond au pourcentage par rapport au CSP d'UNE gare.

```{r}
profil_moyen <- CSP_voya %>%
  group_by(CSP) %>%
  summarise(Pourcentage_moyen = mean(Pourcentage, na.rm = TRUE))


profil_moyen <- profil_moyen %>%
  arrange(desc(Pourcentage_moyen))
profil_moyen

ggplot(profil_moyen, aes(x = reorder(CSP, -Pourcentage_moyen), y = Pourcentage_moyen)) +
  geom_bar(stat = "identity") +
  coord_flip() + 
  labs(title = "Profil Moyen du Voyageur SNCF par CSP",
       x = "Catégorie Socio-Professionnelle",
       y = "Pourcentage Moyen") +
  theme_minimal()
```

## Objets perdus/restitués

Dans cette partie, nous voulons nous intéresser plus particulièrement aux objets.

#### Objets perdus

Tout d'abord, petite visualisation du dataset obj_perdus

```{r}
head(obj_perdus)
summary(obj_perdus)
```

Quelque chose m'interpelle dès le début : c'est la colonne "Type d'enregistrement", il semble que celle-ci est toujours remplie de la même manière

```{r}
enregistrement <- obj_perdus %>%
  select(en = `Type d'enregistrement`)
diff_enre <- n_distinct(enregistrement)
```

C'est donc le cas, donc nous n'utiliserons pas cette colonne .

On distingue aussi que de nombreuses gares ne sont pas présentes.

Nous voulons effectuer plusieurs réductions sur ce jeu de données. Tout d'abord, les informations que nous avons datent de 2019 jusqu'à nos jours. Si nous voulons faire des recoupements avec le dataset de voyageur, nous allons restreindre les dates à 2019 seulement car les années 2020 et 2021 ne sont pas forcément représentatives du traffic ferroviaire normal. L'année 2022 sera analysée prochainement pour voir si une tendance peut commencer à apparaître.

```{r}
obj_perdus_2019 <- obj_perdus %>%
  select(date = `Date de la déclaration de perte`, gare = "Gare", UIC = "Code UIC", nature = "Nature d'objets", type = "Type d'objets") %>%
  filter(date < ymd(20200101)) %>% 
  filter(date > ymd(20190101))
count(obj_perdus_2019)
```

Nous avons donc maintenant 185 065 entrées dans notre dataframe.

Découvrons ce que celui-ci nous cache dans la répartition des objets perdus :

```{r}
obj_perdus_2019 %>% 
  ggplot(aes(y=fct_rev(fct_infreq(type)))) +
  geom_bar() +
  labs(title = "Nombre d'objets perdus par type d'objets en 2019",
       y = "Type d'objet",
       x = "Nombre d'objets perdus en unité")+
  theme_minimal() +
  theme(axis.text.y = element_text(size = rel(0.8)))
```

Sans surprise, les objets les plus couramment perdus sont donc dans l'ordre :

-   Bagages

-   Appareils électroniques

-   Vêtements

```{r}
obj_perdus_trouves <- obj_perdus_2019 %>%
  filter(is.na(gare) == FALSE)

count(obj_perdus_trouves)
```

```{r}
obj_perdus_trouves %>% 
  ggplot(aes(y=fct_rev(fct_infreq(type)))) +
  geom_bar() +
  labs(title = "Nombre d'objets perdus retrouvés par type d'objets en 2019",
       y = "Type d'objet",
       x = "Nombre d'objets perdus en unité") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = rel(0.8)))
```

#### Objets restitués

Nous allons ensuite parcourir le dataset 7 : obj_trouves

```{r}
obj_trouves_2019 <- obj_trouves %>%
  select(date = `Date`,restitution = `Date et heure de restitution` ,gare = "Gare", UIC = "Code UIC", nature = "Nature d'objets", type = "Type d'objets") %>%
  filter(date < ymd(20200101)) %>% 
  filter(date > ymd(20190101))
count(obj_trouves_2019)
```

On découvre donc qu'il y a plus d'objets trouvés que d'objets perdus rendus. Cela veut donc dire que tous les objets récupérés ne sont pas forcément déclarés comme perdus au préalable.

```{r}
obj_trouves_rendus <- obj_trouves_2019 %>%
  filter(is.na(UIC) == FALSE)

count(obj_trouves_rendus)

```

On voit qu'il y a 19 objets rendus qui n'ont pas été identifiés par des code UIC ce qui est étrange. Voyons cela de plus près :

```{r}
obj_trouves_sans_UIC <- obj_trouves_2019 %>%
  filter(is.na(UIC) == TRUE)

obj_trouves_sans_UIC
```

En voyant que la gare n'est pas présente non plus, on peut juger ce rendu comme ayant été entré dans la database sans qu'il n'ait été rendu dans une gare. On peut supposer un rendu dans le train juste après la perte.

Nous allons maintenant essayer de comprendre ce qu'est ce code UIC et s'il y a une relation entre les codes UIC des pertes et des objets trouvés.

Nous allons donc comparer les 2 listes de code UIC

```{r}
liste_UIC_perdus <- obj_perdus_trouves %>%
  select(UIC)
liste_UIC_trouves <- obj_trouves_rendus %>%
  select(UIC)
count(intersect(liste_UIC_perdus, liste_UIC_trouves))
count(setdiff(liste_UIC_perdus,liste_UIC_trouves))
```

Il semble que seulement 146 code UIC différents et après quelques recherches en ligne, le code UIC est l'ID des gares. Donc cette colonne ne nous est pas forcément utile.

Nous allons donc maintenant essayer de mettre en relation plutôt les dates entre les 2 datasets :

```{r}
liste_date_perdus <- obj_perdus_trouves %>%
  select(date)
liste_date_trouves <- obj_trouves_rendus %>%
  select(date)
intersect(liste_date_perdus, liste_date_trouves)
setdiff(liste_date_perdus,liste_date_trouves)
```

Nous avons donc seulement 302 dates en commun entre les 2 jeux de données ce qui est très faible. On peut donc supposer que les 2 datasets ne sont pas liés et les dates ne correspondent pas. On peut supposer que la date des objets perdus provient du questionnaire de perte que les voyageurs remplissent, tandis que la date des objets trouvés provient du formulaire remplit par les agents SNCF.

Nous ne pouvons donc pas faire de relation directe entre un objet déclaré comme perdu et un objet déclaré comme trouvé.

Il est donc difficile de faire des hypothèses très spécifique sur les probabilités de retrouver un objet perdu. La façon de faire ça serait de connaître un nombre précis de pertes et sur ces pertes savoir combien d'entre elles ont été rendues. Sans le lien entre les pertes et les objets rendus, énormément de biais peuvent apparaître. Pour faire les prochaines probabilités, nous allons faire l'hypothèse que l'ensemble des objets rendus ont fait l'objet d'une entrée dans le formulaire de perte.

#### Probabilité de retrouver un objet perdu

*Quelles sont les chances de retrouver un objet perdu ?*

Pour cette première probabilité nous allons faire un calcul simple :

(Nombre d'objets retrouvés / Nombre d'objets perdus) \*100

Cela s'exprime ainsi :

```{r}
proba_commune <- (count(obj_trouves_2019) / count(obj_perdus_2019) * 100)
proba_commune
```

Je trouve la probabilité relativement élevée car pas très éloignée du 50%. Peut-être aussi que le postulat personnel avant le calcul était relativement pessimiste.

#### Probabilité de retrouver un objet selon son type

*Quelles sont les chances de retrouver un objet en fonction de son type ?*

Afin d'avoir une probabilité selon le type il faut donc que nous effectuons la même opération que précédemment avec comme paramètre le type de l'objet.

N.B. la "nature" dans l'intitulé de la question a été changé en type car la nature entrée dans le formulaire des objets trouvés est trop spécifique.

```{r}
type_obj_perdus <- obj_perdus_2019 %>%
  select(type)
type_obj_trouves <- obj_trouves_2019 %>%
  select(type)
occurences_perdus <- table(type_obj_perdus)
occurences_trouves <- table(type_obj_trouves)
probas_types <- occurences_trouves / occurences_perdus * 100
probas_types <- as.data.frame.table(probas_types)
colnames(probas_types)
probas_types %>% 
  ggplot(aes(x=type_obj_trouves, y=Freq)) +
  geom_col() + 
  ylim(0,100) +
  labs(title = "Fréquence de rendu d'objets perdus par type",
       y = "Fréquence de retour",
       x = "Type d'objet",) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = rel(2)),
    axis.text.x = element_text(
      size = rel(0.65),
      face = "italic",
      angle = 45,
      vjust = 1,
      hjust = 1
    )
  )
```
